{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION DES RETARDS DE VOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORT DES LIBRAIRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as npimport \n",
    "from os.path import join as join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHARGEMENT DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data = pd.read_csv(join('data','2016_01.csv'))\n",
    "\n",
    "# Load all CSVs into the \"dfs\" variable\n",
    "dfs = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    file = f\"data/2016_{month:02}.csv\"\n",
    "    try:\n",
    "        tmp = pd.read_csv(file, on_bad_lines='warn', low_memory=False)\n",
    "        dfs.append(tmp)\n",
    "        print(f\"Loaded {file} ✅\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError for {file}: {e}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Concat all dataframes in \"full_df\"\n",
    "df_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total rows in full_df: {len(df_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_data.drop_duplicates()\n",
    "\n",
    "# liste blanche des colonnes\n",
    "df_filtered = df_filtered[[\n",
    "    \"YEAR\",\n",
    "#    \"QUARTER\",\n",
    "    \"MONTH\",\n",
    "    \"DAY_OF_MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "#    \"FL_DATE\",\n",
    "#    \"UNIQUE_CARRIER\",\n",
    "    \"AIRLINE_ID\",\n",
    "#    \"CARRIER\",\n",
    "#    \"TAIL_NUM\",\n",
    "#    \"FL_NUM\",\n",
    "    \"ORIGIN_AIRPORT_ID\",\n",
    "#    \"ORIGIN_AIRPORT_SEQ_ID\",\n",
    "#    \"ORIGIN_CITY_MARKET_ID\",\n",
    "#    \"ORIGIN\",\n",
    "#    \"ORIGIN_CITY_NAME\",\n",
    "#    \"ORIGIN_STATE_ABR\",\n",
    "#    \"ORIGIN_STATE_FIPS\",\n",
    "#    \"ORIGIN_STATE_NM\",\n",
    "#    \"ORIGIN_WAC\",\n",
    "    \"DEST_AIRPORT_ID\",\n",
    "#    \"DEST_AIRPORT_SEQ_ID\",\n",
    "#    \"DEST_CITY_MARKET_ID\",\n",
    "#    \"DEST\",\n",
    "#    \"DEST_CITY_NAME\",\n",
    "#    \"DEST_STATE_ABR\",\n",
    "#    \"DEST_STATE_FIPS\",\n",
    "#    \"DEST_STATE_NM\",\n",
    "#    \"DEST_WAC\",\n",
    "    \"CRS_DEP_TIME\",\n",
    "#    \"DEP_TIME\",\n",
    "    \"DEP_DELAY\",\n",
    "#    \"DEP_DELAY_NEW\",\n",
    "#    \"DEP_DEL15\",\n",
    "#    \"DEP_DELAY_GROUP\",\n",
    "    \"DEP_TIME_BLK\",\n",
    "#    \"TAXI_OUT\",\n",
    "#    \"WHEELS_OFF\",\n",
    "#    \"WHEELS_ON\",\n",
    "#    \"TAXI_IN\",\n",
    "    \"CRS_ARR_TIME\",\n",
    "#    \"ARR_TIME\",\n",
    "#    \"ARR_DELAY\",\n",
    "#    \"ARR_DELAY_NEW\",\n",
    "    \"ARR_DEL15\",\n",
    "#   \"ARR_DELAY_GROUP\",\n",
    "    \"ARR_TIME_BLK\",\n",
    "#    \"CANCELLED\",\n",
    "#   \"CANCELLATION_CODE\",\n",
    "#    \"DIVERTED\",\n",
    "    \"CRS_ELAPSED_TIME\",\n",
    "#    \"ACTUAL_ELAPSED_TIME\",\n",
    "#    \"AIR_TIME\",\n",
    "    ]]\n",
    "\n",
    "# on supprime les lignes avec des valeurs manquantes (constatées sur les colonnes de retard au départ et de retard à l'arrivée)\n",
    "df_filtered = df_filtered.dropna(subset=['DEP_DELAY', 'ARR_DEL15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EXPLORATION DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix avant filtres est TROP consommateur de CPU\n",
    "\n",
    "\n",
    "# matrix pour les données manquantes\n",
    "# voir png généré plot.png\n",
    "#fig = msno.matrix(df_data)\n",
    "#fig_copy = fig.get_figure()\n",
    "#fig_copy.savefig('plot.png', bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"Info après filtre :\")\n",
    "print(df_filtered.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"Describe après filtre :\")\n",
    "print(df_filtered.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyse des données avec sns\n",
    "# histplot pour analyser les données\n",
    "sns.histplot(df_filtered['ARR_DEL15'], kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot pour détecter les outliers\n",
    "sns.boxplot(x=df_filtered['DEP_DELAY'])\n",
    "plt.show()\n",
    "sns.boxplot(x=df_filtered['CRS_ELAPSED_TIME'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# on supprime la ligne que l'on a identifé comme incohérente\n",
    "# Filtrer les lignes où le mois est supérieur à 12\n",
    "df_filtered = df_filtered[df_filtered['MONTH'] < 13]\n",
    "\n",
    "print(f\"Nombre de vol dans df_filtered: {len(df_filtered)}\")\n",
    "print(f\"Nombre de vol en retard à l'arrivée: {len(df_filtered[df_filtered.ARR_DEL15 == 1]) * 100 / len(df_filtered)} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va créer une liste d'aéroport\n",
    "df_aeroport_orig = df_data[[\n",
    "    \"ORIGIN_AIRPORT_ID\",\n",
    "#    \"ORIGIN_AIRPORT_SEQ_ID\",\n",
    "    \"ORIGIN_CITY_MARKET_ID\",\n",
    "    \"ORIGIN\",\n",
    "    \"ORIGIN_CITY_NAME\",\n",
    "    \"ORIGIN_STATE_ABR\",\n",
    "    \"ORIGIN_STATE_FIPS\",\n",
    "    \"ORIGIN_STATE_NM\",\n",
    "    \"ORIGIN_WAC\",\n",
    "]]\n",
    "df_aeroport_dest = df_data[[\n",
    "    \"DEST_AIRPORT_ID\",\n",
    "#    \"DEST_AIRPORT_SEQ_ID\",\n",
    "    \"DEST_CITY_MARKET_ID\",\n",
    "    \"DEST\",\n",
    "    \"DEST_CITY_NAME\",\n",
    "    \"DEST_STATE_ABR\",\n",
    "    \"DEST_STATE_FIPS\",\n",
    "    \"DEST_STATE_NM\",\n",
    "    \"DEST_WAC\",\n",
    "]]\n",
    "df_aeroport_orig = df_aeroport_orig.drop_duplicates()\n",
    "df_aeroport_dest = df_aeroport_dest.drop_duplicates()\n",
    "# Renommer la colonne\n",
    "df_aeroport_orig = df_aeroport_orig.rename(columns={'ORIGIN_AIRPORT_ID': 'AIRPORT_ID', 'ORIGIN_CITY_MARKET_ID': 'CITY_MARKET_ID', 'ORIGIN': 'ORIGIN', 'ORIGIN_CITY_NAME': 'CITY_NAME', 'ORIGIN_STATE_ABR': 'STATE_ABR', 'ORIGIN_STATE_FIPS': 'STATE_FIPS', 'ORIGIN_STATE_NM': 'STATE_NM', 'ORIGIN_WAC': 'WAC'})\n",
    "df_aeroport_dest = df_aeroport_dest.rename(columns={'DEST_AIRPORT_ID': 'AIRPORT_ID', 'DEST_CITY_MARKET_ID': 'CITY_MARKET_ID', 'DEST': 'ORIGIN', 'DEST_CITY_NAME': 'CITY_NAME', 'DEST_STATE_ABR': 'STATE_ABR', 'DEST_STATE_FIPS': 'STATE_FIPS', 'DEST_STATE_NM': 'STATE_NM', 'DEST_WAC': 'WAC'})\n",
    "\n",
    "\n",
    "df_all_aeroport = pd.merge(df_aeroport_dest, df_aeroport_orig).drop_duplicates()\n",
    "df_all_aeroport = df_all_aeroport.reset_index(drop=True)\n",
    "\n",
    "print(f\"Nombre d'aéroport dans df_all_aeroport: {len(df_all_aeroport)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va créer une liste de conpagnie aérienne\n",
    "df_compagnie = df_data[[\n",
    "    \"AIRLINE_ID\",\n",
    "    \"UNIQUE_CARRIER\",\n",
    "    \"CARRIER\"\n",
    "]]\n",
    "df_compagnie = df_compagnie.drop_duplicates()\n",
    "df_compagnie = df_compagnie.reset_index(drop=True)\n",
    "\n",
    "# on supprime les lignes avec des valeurs incohérentes\n",
    "indexToDrop = df_compagnie[df_compagnie['AIRLINE_ID'] > 99999].index\n",
    "df_compagnie = df_compagnie.drop(indexToDrop)\n",
    "\n",
    "print(f\"Nombre de compagnie dans df_compagnie: {len(df_compagnie)}\")\n",
    "print(\"Compagnies :\")\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df_compagnie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VISUALISATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix pour les données manquantes\n",
    "# voir png généré plot.png\n",
    "fig = msno.matrix(df_filtered)\n",
    "fig_copy = fig.get_figure()\n",
    "fig_copy.savefig('plot.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.MODÉLISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
